# Contiv-VPP deployment YAML file. This deploys Contiv VPP networking on a Kuberntes cluster.
# The deployment consists of the following components:
#   - contiv-etcd - deployed on k8s master
#   - contiv-vswitch - deployed on each k8s node
#   - contiv-ksr - deployed on k8s master

###########################################################
#  Configuration
###########################################################

# This config map contains contiv-agent configuration. The most important part is the IPAMConfig,
# which may be updated in case the default IPAM settings do not match your needs.
# NodeConfig may be used in case your nodes have more than 1 VPP interface. In that case, one
# of them needs to be marked as the main inter-node interface, and the rest of them can be
# configured with any IP addresses (the IPs cannot conflict with the main IPAM config).
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-agent-cfg
  namespace: kube-system
data:
  contiv.yaml: |-
    TCPstackDisabled: {{ .Values.contiv.tcpStackDisabled }}
    UseTAPInterfaces: {{ .Values.contiv.useTAPInterfaces }}
    TAPInterfaceVersion: {{ .Values.contiv.tapInterfaceVersion }}
    {{- if .Values.contiv.stealInterface }}
    StealInterface: {{ .Values.contiv.stealInterface }}
    {{- end }}
    {{- if .Values.contiv.stealFirstNIC }}
    StealFirstNIC: True
    {{- end }}
    NatExternalTraffic: {{ .Values.contiv.natExternalTraffic }}
    MTUSize: {{ .Values.contiv.mtuSize }}
    {{- if .Values.contiv.cleanupIdleNATSessions }}
    CleanupIdleNATSessions: True
    TCPNATSessionTimeout: {{ .Values.contiv.tcpNATSessionTimeout }}
    OtherNATSessionTimeout: {{ .Values.contiv.otherNATSessionTimeout }}
    {{- end }}
    ScanIPNeighbors: {{ .Values.contiv.scanIPNeighbors }}
    IPNeighborScanInterval: {{ .Values.contiv.ipNeighborScanInterval }}
    IPNeighborStaleThreshold: {{ .Values.contiv.ipNeighborStaleThreshold }}
    {{- if .Values.contiv.serviceLocalEndpointWeight }}
    ServiceLocalEndpointWeight: {{ .Values.contiv.serviceLocalEndpointWeight }}
    {{- end }}
    IPAMConfig:
      PodSubnetCIDR: {{ .Values.contiv.ipamConfig.podSubnetCIDR }}
      PodNetworkPrefixLen: {{ .Values.contiv.ipamConfig.podNetworkPrefixLen }}
      PodIfIPCIDR: {{ .Values.contiv.ipamConfig.podIfIPCIDR }}
      VPPHostSubnetCIDR: {{ .Values.contiv.ipamConfig.vppHostSubnetCIDR }}
      VPPHostNetworkPrefixLen: {{ .Values.contiv.ipamConfig.vppHostNetworkPrefixLen }}
      {{- if .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      NodeInterconnectCIDR: {{ .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      {{- end }}
      VxlanCIDR: {{ .Values.contiv.ipamConfig.vxlanCIDR }}
      NodeInterconnectDHCP: {{ if .Values.contiv.ipamConfig.nodeInterconnectCIDR }}False{{ else }}True{{ end }}
      {{- if .Values.contiv.ipamConfig.serviceCIDR }}
      ServiceCIDR: {{ .Values.contiv.ipamConfig.serviceCIDR }}
      {{- end }}

    {{- if .Values.contiv.nodeConfig }}
    NodeConfig:
    {{- range .Values.contiv.nodeConfig }}
    - NodeName: {{ .name }}
      MainVppInterface:
        InterfaceName: {{ .mainInterface.interfaceName }}
        {{- if .mainInterface.useDHCP }}
        UseDHCP: {{ .mainInterface.useDHCP }}
        {{ else }}
        IP: {{ .mainInterface.ip }}
        {{- end -}}
      Gateway: {{ .gateway }}
      {{- if .natExternalTraffic }}
      NatExternalTraffic: {{ .natExternalTraffic }}
      {{- end }}
      {{- if .otherInterfaces }}
      OtherVPPInterfaces:
      {{- range $iface := .otherInterfaces }}
        - InterfaceName: {{ $iface.interfaceName }}
          IP: {{ $iface.ip }}
      {{- end }}
    {{- end }}
    {{- end }}
    {{- end }}
  logs.conf: |
    defaultlevel: {{ .Values.logs.defaultLevel }}
  grpc.conf: |
    socket-type: unix
    endpoint: /var/run/contiv/cni.sock
  http.conf: |
      endpoint: 0.0.0.0:9999
      {{- if .Values.http.enableServerCert }}
      server-cert-file: /var/http/{{ .Values.http.serverCert }}
      server-key-file: /var/http/{{ .Values.http.serverKey }}
      {{- end }}
      {{- if .Values.http.enableBasicAuth }}
      client-basic-auth:
        - {{ .Values.http.basicAuth | quote }}
      {{- end }}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: govpp-cfg
  namespace: kube-system
data:
  govpp.conf: |
    health-check-probe-interval: {{ .Values.govpp.healthCheckProbeInterval | int64 }}
    health-check-reply-timeout: {{ .Values.govpp.healthCheckReplyTimeout | int64 }}
    health-check-threshold: {{ .Values.govpp.healthCheckThreshold | int64 }}
    reply-timeout: {{ .Values.govpp.replyTimeout | int64 }}

---

###########################################################
#
# !!! DO NOT EDIT THINGS BELOW THIS LINE !!!
#
###########################################################


###########################################################
#  Components and other resources
###########################################################

# This installs the contiv-etcd (ETCD server to be used by Contiv) on the master node in a Kubernetes cluster.
# In odrer to dump the content of ETCD, you can use the kubectl exec command similar to this:
#   kubectl exec contiv-etcd-cxqhr -n kube-system etcdctl -- get --endpoints=[127.0.0.1:12379] --prefix="true" ""
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: contiv-etcd
  namespace: kube-system
  labels:
    k8s-app: contiv-etcd
spec:
  serviceName: contiv-etcd
  selector:
    matchLabels:
      k8s-app: contiv-etcd
  updateStrategy:
    type: {{ .Values.etcd.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-etcd
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
      # We need this to schedule on the master no matter what else is going on, so tolerate everything.
      - key: ''
        operator: Exists
        effect: ''
      # This likely isn't needed due to the above wildcard, but keep it in for now.
      - key: CriticalAddonsOnly
        operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true

      containers:
        - name: contiv-etcd
          image: {{ .Values.etcd.image.repository }}:{{ .Values.etcd.image.tag }}
          imagePullPolicy: {{ .Values.etcd.image.pullPolicy }}
          env:
            - name: CONTIV_ETCD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: ETCDCTL_API
              value: "3"
          command:
            - /bin/sh
          args:
            - -c
            - /usr/local/bin/etcd --name=contiv-etcd --data-dir=/var/etcd/contiv-data
            {{- if .Values.etcd.secureTransport }}
              --client-cert-auth --trusted-ca-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.caCert }}
              --cert-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.serverCert }} --key-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.serverKey }}
              --peer-client-cert-auth --peer-trusted-ca-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.caCert }}
              --peer-cert-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.serverCert }} --peer-key-file=/var/etcd/contiv-secrets/{{ .Values.etcd.secrets.serverKey }}
              --advertise-client-urls=https://0.0.0.0:12379 --listen-client-urls=https://0.0.0.0:12379 --listen-peer-urls=https://0.0.0.0:12380
            {{- else }}
              --advertise-client-urls=http://0.0.0.0:12379 --listen-client-urls=http://0.0.0.0:12379 --listen-peer-urls=http://0.0.0.0:12380
            {{- end }}
          volumeMounts:
            - name: var-etcd
              mountPath: /var/etcd/
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/etcd/contiv-secrets
              readOnly: true
            {{- end }}
      {{- if .Values.etcd.secureTransport }}
      volumes:
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: serverCert
              path: {{ .Values.etcd.secrets.serverCert }}
            - key: serverKey
              path: {{ .Values.etcd.secrets.serverKey }}
          {{- end }}
      {{- end }}
{{- if .Values.etcd.usePersistentVolume }}
  volumeClaimTemplates:
  - metadata:
      name: var-etcd
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.etcd.persistentVolumeSize }}
    {{- if .Values.etcd.persistentVolumeStorageClass }}
    {{- if (eq "-" .Values.etcd.persistentVolumeStorageClass) }}
      storageClassName: ""
    {{- else }}
      storageClassName: "{{ .Values.etcd.persistentVolumeStorageClass }}"
    {{- end }}
    {{- end }}
{{- else }}
      {{- if not .Values.etcd.secureTransport }}
      volumes:
      {{- end }}
        - name: var-etcd
          hostPath:
             path: {{ .Values.etcd.dataDir }}
{{- end }}


{{- if .Values.etcd.secureTransport }}
{{- if not .Values.etcd.secrets.mountFromHost }}
---

# The following contains k8s Secrets for use with a TLS enabled etcd cluster.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-etcd-secrets
  namespace: kube-system
data:
  caCert: |-
    {{ .Files.Get .Values.etcd.secrets.caCert | b64enc }}
  serverCert: |-
    {{ .Files.Get .Values.etcd.secrets.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.etcd.secrets.serverKey | b64enc }}
  clientCert: |-
    {{ .Files.Get .Values.etcd.secrets.clientCert | b64enc }}
  clientKey: |-
    {{ .Files.Get .Values.etcd.secrets.clientKey | b64enc }}
{{- end }}
{{- end }}

---

apiVersion: v1
kind: Service
metadata:
  name: contiv-etcd
  namespace: kube-system
spec:
  type: NodePort
  # Match contiv-etcd DaemonSet.
  selector:
    k8s-app: contiv-etcd
  ports:
  - port: 12379
    nodePort: {{ .Values.etcd.service.nodePort }}

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-ksr-http-cfg
  namespace: kube-system
data:
  http.conf: |
    endpoint: 0.0.0.0:9191
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}

---
# This config map contains ETCD configuration for connecting to the contiv-etcd defined above.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-cfg
  namespace: kube-system
data:
  etcd.conf: |
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    dial-timeout: 10000000000
    endpoints:
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"

---

# This config map contains ETCD configuration for connecting to the contiv-etcd defined above with auto comapact.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-withcompact-cfg
  namespace: kube-system
data:
  etcd.conf: |
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/etcd/contiv-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    dial-timeout: 10000000000
    auto-compact: 600000000000
    endpoints:
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"

{{- if .Values.http.enableServerCert }}
{{- if not .Values.http.mountFromHost }}
---

# The following contains k8s Secrets for use with a secured HTTP plugin.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-http-secrets
  namespace: kube-system
data:
  serverCert: |-
    {{ .Files.Get .Values.http.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.http.serverKey | b64enc }}
{{- end }}
{{- end }}

---

# This installs contiv-vswitch on each master and worker node in a Kubernetes cluster.
# It consists of the following containers:
#   - contiv-vswitch container: contains VPP and its management agent
#   - contiv-cni container: installs CNI on the host
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: contiv-vswitch
  namespace: kube-system
  labels:
    k8s-app: contiv-vswitch
spec:
  selector:
    matchLabels:
      k8s-app: contiv-vswitch
  updateStrategy:
    type: {{ .Values.vswitch.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-vswitch
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      - key: CriticalAddonsOnly
        operator: Exists
      hostNetwork: true
      hostPID: true

      # Init containers are executed before regular containers, must finish successfully before regular ones are started.
      initContainers:
      # This container installs the Contiv CNI binaries
      # and CNI network config file on each node.
      - name: contiv-cni
        image: {{ .Values.cni.image.repository }}:{{ default .Chart.Version .Values.cni.image.tag }}
        imagePullPolicy: IfNotPresent
        env:
          - name: SLEEP
            value: "false"
        volumeMounts:
          - mountPath: /opt/cni/bin
            name: cni-bin-dir
          - mountPath: /etc/cni/net.d
            name: cni-net-dir
      # This init container waits until etcd is started
      - name: wait-foretcd
        env:
          - name: ETCDPORT
            value: {{ .Values.etcd.service.nodePort | quote }}
        image: busybox
        command: ['sh', '-c', 'until nc -w 2 127.0.0.1:$ETCDPORT; do echo waiting for etcd; sleep 2; done;']
      # This init container extracts/copies VPP LD_PRELOAD libs and default VPP config to the host.
      - name: vpp-init
        image: {{ .Values.vswitch.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
        imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
        command:
        - /bin/sh
        args:
        - -c
        - |
          set -eu
          chmod 700 /run/vpp
          rm -rf /dev/shm/db /dev/shm/global_vm /dev/shm/vpe-api
          if [ ! -e /host/etc/vpp/contiv-vswitch.conf ]; then
              cp /etc/vpp/contiv-vswitch.conf /host/etc/vpp/
          fi
          if [ ! -d /var/run/contiv ]; then
              mkdir /var/run/contiv
          fi
          chmod 700 /var/run/contiv
          rm -f /var/run/contiv/cni.sock
          if ip link show vpp1 >/dev/null 2>&1; then
               ip link del vpp1
          fi
          cp -f /usr/local/bin/vppctl /host/usr/local/bin/vppctl
        resources: {}
        securityContext:
          privileged: true
        volumeMounts:
          - name: usr-local-bin
            mountPath: /host/usr/local/bin
          - name: vpp-lib64
            mountPath: /vpp-lib64/
          - name: vpp-cfg
            mountPath: /host/etc/vpp
          - name: shm
            mountPath: /dev/shm
          - name: vpp-run
            mountPath: /run/vpp
          - name: contiv-run
            mountPath: /var/run/contiv

      containers:
        # Runs contiv-vswitch container on each Kubernetes node.
        # It contains the vSwitch VPP and its management agent.
        - name: contiv-vswitch
          image: {{ .Values.vswitch.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
          imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
          securityContext:
            privileged: true
          ports:
            # readiness + liveness probe
            - containerPort: 9999
          {{- if .Values.vswitch.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9999
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: 3
            timeoutSeconds: 2
            failureThreshold: 3
            initialDelaySeconds: 15
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9999
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: 3
            timeoutSeconds: 2
            failureThreshold: 3
            initialDelaySeconds: 60
          {{- end }}
          env:
            - name: MICROSERVICE_LABEL
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: ETCDV3_CONFIG
              value: "/etc/etcd/etcd.conf"
          volumeMounts:
            - name: etcd-cfg
              mountPath: /etc/etcd
              {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/etcd/contiv-secrets
              readOnly: true
              {{- end }}
              {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
              {{- end }}
            - name: vpp-cfg
              mountPath: /etc/vpp
            - name: shm
              mountPath: /dev/shm
            - name: dev
              mountPath: /dev
            - name: vpp-run
              mountPath: /run/vpp
            - name: contiv-run
              mountPath: /var/run/contiv
            - name: contiv-plugin-cfg
              mountPath: /etc/agent
            - name: govpp-plugin-cfg
              mountPath: /etc/govpp
          {{- if .Values.vswitch.defineMemoryLimits }}
          resources:
             limits:
               hugepages-2Mi: {{ .Values.vswitch.hugePages2miLimit }}
               memory: {{ .Values.vswitch.memoryLimit }}
          {{- end }}

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-cfg
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # VPP startup config folder.
        - name: vpp-cfg
          hostPath:
            path: /etc/vpp
        # To install vppctl.
        - name: usr-local-bin
          hostPath:
            path: /usr/local/bin
        # LD_PRELOAD library.
        - name: vpp-lib64
          hostPath:
            path: /tmp/ldpreload/vpp-lib64
        # /dev mount is required for DPDK-managed NICs on VPP (/dev/uio0) and for shared memory communication with VPP (/dev/shm)
        - name: dev
          hostPath:
            path: /dev
        - name: shm
          hostPath:
            path: /dev/shm
        # For CLI unix socket.
        - name: vpp-run
          hostPath:
            path: /run/vpp
        # For CNI / STN unix domain socket
        - name: contiv-run
          hostPath:
            path: /var/run/contiv
        # Used to configure contiv plugin.
        - name: contiv-plugin-cfg
          configMap:
            name: contiv-agent-cfg
        # Used to configure govpp plugin.
        - name: govpp-plugin-cfg
          configMap:
            name: govpp-cfg

---

# This installs the contiv-ksr (Kubernetes State Reflector) on the master node in a Kubernetes cluster.
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: contiv-ksr
  namespace: kube-system
  labels:
    k8s-app: contiv-ksr
spec:
  updateStrategy:
    type: {{ .Values.ksr.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-ksr
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      - key: CriticalAddonsOnly
        operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true
      # This grants the required permissions to contiv-ksr.
      serviceAccountName: contiv-ksr

      initContainers:
        # This init container waits until etcd is started
        - name: wait-foretcd
          env:
          - name: ETCDPORT
            value: {{ .Values.etcd.service.nodePort | quote }}
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 127.0.0.1:$ETCDPORT; do echo waiting for etcd; sleep 2; done;']

      containers:
        - name: contiv-ksr
          image: {{ .Values.ksr.image.repository }}:{{ default .Chart.Version .Values.ksr.image.tag }}
          imagePullPolicy: {{ .Values.ksr.image.pullPolicy }}
          env:
            - name: ETCDV3_CONFIG
              value: "/etc/etcd/etcd.conf"
            - name: HTTP_CONFIG
              value: "/etc/http/http.conf"
          volumeMounts:
            - name: etcd-cfg
              mountPath: /etc/etcd
            - name: http-cfg
              mountPath: /etc/http
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/etcd/contiv-secrets
              readOnly: true
            {{- end }}
            {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
            {{- end }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9191
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: 1
            initialDelaySeconds: 10
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9191
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: 1
            initialDelaySeconds: 30

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-withcompact-cfg
        - name: http-cfg
          configMap:
            name: contiv-ksr-http-cfg
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}

---

# This cluster role defines a set of permissions required for contiv-ksr.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: contiv-ksr
  namespace: kube-system
rules:
  - apiGroups:
    - ""
    - extensions
    resources:
      - pods
      - namespaces
      - networkpolicies
      - services
      - endpoints
      - nodes
    verbs:
      - watch
      - list

---

# This defines a service account for contiv-ksr.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-ksr
  namespace: kube-system

---

# This binds the contiv-ksr cluster role with contiv-ksr service account.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-ksr
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-ksr
subjects:
- kind: ServiceAccount
  name: contiv-ksr
  namespace: kube-system
