# Contiv-VPP deployment YAML file. This deploys Contiv VPP networking on a Kuberntes cluster.
# The deployment consists of the following components:
#   - contiv-etcd - deployed on k8s master
#   - contiv-vswitch - deployed on each k8s node
#   - contiv-ksr - deployed on k8s master

###########################################################
#  Configuration
###########################################################

# This config map contains contiv-agent configuration. The most important part is the ipamConfig,
# which may be updated in case the default IPAM settings do not match your needs.
# nodeConfig may be used in case your nodes have more than 1 VPP interface. In that case, one
# of them needs to be marked as the main inter-node interface, and the rest of them can be
# configured with any IP addresses (the IPs cannot conflict with the main IPAM config).
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-agent-cfg
  namespace: kube-system
data:
  contiv.conf: |-
    useTAPInterfaces: {{ .Values.contiv.useTAPInterfaces }}
    tapInterfaceVersion: {{ .Values.contiv.tapInterfaceVersion }}
    {{- if eq (.Values.contiv.tapInterfaceVersion | int) 2 }}
    tapv2RxRingSize: {{ .Values.contiv.tapv2RxRingSize }}
    tapv2TxRingSize: {{ .Values.contiv.tapv2TxRingSize }}
    {{- end }}
    {{- if ne (.Values.contiv.vmxnet3RxRingSize | int) 1024 }}
    vmxnet3RxRingSize: {{ .Values.contiv.vmxnet3RxRingSize }}
    {{- end }}
    {{- if ne (.Values.contiv.vmxnet3TxRingSize | int) 1024 }}
    vmxnet3TxRingSize: {{ .Values.contiv.vmxnet3TxRingSize }}
    {{- end }}
    {{- if ne .Values.contiv.interfaceRxMode "default" }}
    interfaceRxMode: {{ .Values.contiv.interfaceRxMode }}
    {{- end }}
    tcpChecksumOffloadDisabled: true
    {{- if .Values.contiv.stealInterface }}
    stealInterface: {{ .Values.contiv.stealInterface }}
    {{- end }}
    {{- if .Values.contiv.stealFirstNIC }}
    stealFirstNIC: True
    {{- end }}
    natExternalTraffic: {{ .Values.contiv.natExternalTraffic }}
    mtuSize: {{ .Values.contiv.mtuSize }}
    scanIPNeighbors: {{ .Values.contiv.scanIPNeighbors }}
    ipNeighborScanInterval: {{ .Values.contiv.ipNeighborScanInterval }}
    ipNeighborStaleThreshold: {{ .Values.contiv.ipNeighborStaleThreshold }}
    enablePacketTrace: {{ .Values.contiv.enablePacketTrace }}
    routeServiceCIDRToVPP: {{ .Values.contiv.routeServiceCIDRToVPP }}
    crdNodeConfigurationDisabled: {{ .Values.contiv.crdNodeConfigurationDisabled }}
    ipamConfig:
      {{- if .Values.contiv.ipamConfig.contivCIDR }}
      contivCIDR: {{ .Values.contiv.ipamConfig.contivCIDR }}
      {{ else }}
      nodeInterconnectDHCP: {{ .Values.contiv.ipamConfig.nodeInterconnectDHCP }}
      {{- if .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      nodeInterconnectCIDR: {{ .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      {{- end }}
      {{- if .Values.contiv.ipamConfig.serviceCIDR }}
      serviceCIDR: {{ .Values.contiv.ipamConfig.serviceCIDR }}
      {{- end }}
      podSubnetCIDR: {{ .Values.contiv.ipamConfig.podSubnetCIDR }}
      podSubnetOneNodePrefixLen: {{ .Values.contiv.ipamConfig.podSubnetOneNodePrefixLen }}
      podVPPSubnetCIDR: {{ .Values.contiv.ipamConfig.podVPPSubnetCIDR }}
      vppHostSubnetCIDR: {{ .Values.contiv.ipamConfig.vppHostSubnetCIDR }}
      vppHostSubnetOneNodePrefixLen: {{ .Values.contiv.ipamConfig.vppHostSubnetOneNodePrefixLen }}
      vxlanCIDR: {{ .Values.contiv.ipamConfig.vxlanCIDR }}
      {{- end }}
    {{- if .Values.contiv.nodeConfig }}
    nodeConfig:
    {{- range .Values.contiv.nodeConfig }}
    - nodeName: {{ .name }}
      mainVPPInterface:
        interfaceName: {{ .mainInterface.interfaceName }}
        {{- if .mainInterface.useDHCP }}
        useDHCP: {{ .mainInterface.useDHCP }}
        {{- end -}}
        {{- if .mainInterface.ip }}
        ip: {{ .mainInterface.ip }}
        {{- end -}}
      {{- if .natExternalTraffic }}
      natExternalTraffic: {{ .natExternalTraffic }}
      {{- end }}
      {{- if .gateway }}
      gateway: {{ .gateway }}
      {{- end -}}
      {{- if .stealInterface }}
      stealInterface: {{ .stealInterface }}
      {{- end -}}
      {{- if .otherInterfaces }}
      otherVPPInterfaces:
      {{- range $iface := .otherInterfaces }}
        - interfaceName: {{ $iface.interfaceName }}
          ip: {{ $iface.ip }}
      {{- end }}
      {{- end }}
    {{- end }}
    {{- end }}
  controller.conf: |
    delayLocalResync: {{ .Values.controller.delayLocalResync | int64 }}
    enablePeriodicHealing: {{ .Values.controller.enablePeriodicHealing }}
    periodicHealingInterval: {{ .Values.controller.periodicHealingInterval | int64 }}
    recordEventHistory: {{ .Values.controller.recordEventHistory }}
    eventHistoryAgeLimit: {{ .Values.controller.eventHistoryAgeLimit }}
  service.conf: |
    {{- if .Values.contiv.cleanupIdleNATSessions }}
    cleanupIdleNATSessions: true
    tcpNATSessionTimeout: {{ .Values.contiv.tcpNATSessionTimeout }}
    otherNATSessionTimeout: {{ .Values.contiv.otherNATSessionTimeout }}
    {{- end }}
    {{- if .Values.contiv.serviceLocalEndpointWeight }}
    serviceLocalEndpointWeight: {{ .Values.contiv.serviceLocalEndpointWeight }}
    {{- end }}
    disableNATVirtualReassembly: {{ .Values.contiv.disableNATVirtualReassembly }}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: vpp-agent-cfg
  namespace: kube-system
data:
  govpp.conf: |
    health-check-probe-interval: {{ .Values.govpp.healthCheckProbeInterval | int64 }}
    health-check-reply-timeout: {{ .Values.govpp.healthCheckReplyTimeout | int64 }}
    health-check-threshold: {{ .Values.govpp.healthCheckThreshold | int64 }}
    reply-timeout: {{ .Values.govpp.replyTimeout | int64 }}
  logs.conf: |
    default-level: {{ .Values.logs.defaultLevel }}
    loggers:
      - name: statscollector
        level: info
      - name: vpp.if-state
        level: info
      - name: linux.arp-conf
        level: info
      - name: vpp-rest
        level: info
  grpc.conf: |
    network: unix
    endpoint: /var/run/contiv/cni.sock
    force-socket-removal: true
    permission: 700
  http.conf: |
    endpoint: 0.0.0.0:9999
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}
  bolt.conf: |
    db-path: /var/bolt/bolt.db
    file-mode: 432
    lock-timeout: 0
  telemetry.conf: |
    polling-interval: {{ .Values.telemetry.pollingInterval | int64 }}
    disabled: {{ .Values.telemetry.disabled }}
  linux-ifplugin.conf: |
    dump-go-routines-count: 5
  linux-l3plugin.conf: |
    dump-go-routines-count: 5
  kvscheduler.conf: |
    record-transaction-history: {{ .Values.controller.recordEventHistory }}
    transaction-history-age-limit: {{ .Values.controller.eventHistoryAgeLimit }}

---

###########################################################
#
# !!! DO NOT EDIT THINGS BELOW THIS LINE !!!
#
###########################################################


###########################################################
#  Components and other resources
###########################################################

# This installs the contiv-etcd (ETCD server to be used by Contiv) on the master node in a Kubernetes cluster.
# In odrer to dump the content of ETCD, you can use the kubectl exec command similar to this:
#   kubectl exec contiv-etcd-cxqhr -n kube-system etcdctl -- get --endpoints=[127.0.0.1:12379] --prefix="true" ""
{{- define "utils.commaseparated" -}}
{{- $local := dict "first" true -}}
{{- range $k, $v := . -}}{{- if not $local.first -}},{{- end -}}{{- $v -}}{{- $_ := set $local "first" false -}}{{- end -}}
{{- end }}
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: contiv-etcd
  namespace: kube-system
  labels:
    k8s-app: contiv-etcd
spec:
  serviceName: contiv-etcd
  selector:
    matchLabels:
      k8s-app: contiv-etcd
  updateStrategy:
    type: {{ .Values.etcd.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-etcd
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true

      containers:
        - name: contiv-etcd
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.etcd_arm64.image.repository }}:{{ .Values.etcd_arm64.image.tag }}
          {{- else }}
          image: {{ .Values.etcd.image.repository }}:{{ .Values.etcd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.etcd.image.pullPolicy }}
          env:
            - name: CONTIV_ETCD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: ETCDCTL_API
              value: "3"
            {{- if .Values.Arm64Platform }}
            - name: ETCD_UNSUPPORTED_ARCH
              value: "arm64"
            {{- end }}
            {{- if .Values.etcd.secureTransport }}
            - name: ETCDCTL_CACERT
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
            - name: ETCDCTL_CERT
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
            - name: ETCDCTL_KEY
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
            {{- end }}
          command:
            - /bin/sh
          args:
            - -c
            - /usr/local/bin/etcd --name=contiv-etcd --data-dir=/var/etcd/contiv-data
            {{- if .Values.etcd.secureTransport }}
              --client-cert-auth --trusted-ca-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
              --cert-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverCert }} --key-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverKey }}
              --peer-client-cert-auth --peer-trusted-ca-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
              --peer-cert-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverCert }} --peer-key-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverKey }}
              --advertise-client-urls=https://0.0.0.0:12379 --listen-client-urls=https://0.0.0.0:12379 --listen-peer-urls=https://0.0.0.0:12380
              {{- if .Values.etcd.cipherSuites }}
              --cipher-suites {{ include "utils.commaseparated" .Values.etcd.cipherSuites }}
              {{- end }}
            {{- else }}
              --advertise-client-urls=http://0.0.0.0:12379 --listen-client-urls=http://0.0.0.0:12379 --listen-peer-urls=http://0.0.0.0:12380
            {{- end }}
          volumeMounts:
            - name: var-etcd
              mountPath: /var/etcd/
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
          {{- if .Values.etcd.enableLivenessProbe }}
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - etcdctl get --endpoints=127.0.0.1:{{ .Values.etcd.service.nodePort }} /
            periodSeconds: {{ .Values.etcd.probePeriodSeconds }}
            initialDelaySeconds: {{ .Values.etcd.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.etcd.cpuLimit }}
            limits:
              cpu: {{ .Values.etcd.cpuLimit }}
            {{- end }}
            {{- if .Values.etcd.cpuRequest }}
            requests:
              cpu: {{ .Values.etcd.cpuRequest }}
            {{- end }}
      {{- if .Values.etcd.secureTransport }}
      volumes:
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: serverCert
              path: {{ .Values.etcd.secrets.serverCert }}
            - key: serverKey
              path: {{ .Values.etcd.secrets.serverKey }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
      {{- end }}
{{- if .Values.etcd.usePersistentVolume }}
  volumeClaimTemplates:
  - metadata:
      name: var-etcd
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.etcd.persistentVolumeSize }}
    {{- if .Values.etcd.persistentVolumeStorageClass }}
    {{- if (eq "-" .Values.etcd.persistentVolumeStorageClass) }}
      storageClassName: ""
    {{- else }}
      storageClassName: "{{ .Values.etcd.persistentVolumeStorageClass }}"
    {{- end }}
    {{- end }}
{{- else }}
      {{- if not .Values.etcd.secureTransport }}
      volumes:
      {{- end }}
        - name: var-etcd
          hostPath:
            path: {{ .Values.etcd.dataDir }}
{{- end }}


{{- if .Values.etcd.secureTransport }}
{{- if not .Values.etcd.secrets.mountFromHost }}
---

# The following contains k8s Secrets for use with a TLS enabled etcd cluster.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-etcd-secrets
  namespace: kube-system
data:
  caCert: |-
    {{ .Files.Get .Values.etcd.secrets.caCert | b64enc }}
  serverCert: |-
    {{ .Files.Get .Values.etcd.secrets.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.etcd.secrets.serverKey | b64enc }}
  clientCert: |-
    {{ .Files.Get .Values.etcd.secrets.clientCert | b64enc }}
  clientKey: |-
    {{ .Files.Get .Values.etcd.secrets.clientKey | b64enc }}
{{- end }}
{{- end }}

---

apiVersion: v1
kind: Service
metadata:
  name: contiv-etcd
  namespace: kube-system
spec:
  type: NodePort
  # Match contiv-etcd DaemonSet.
  selector:
    k8s-app: contiv-etcd
  ports:
    - port: 12379
      nodePort: {{ .Values.etcd.service.nodePort }}

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-ksr-http-cfg
  namespace: kube-system
data:
  http.conf: |
    endpoint: 0.0.0.0:9191
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}

---
# This config map contains ETCD configuration for connecting to the contiv-etcd defined above.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-cfg
  namespace: kube-system
data:
  etcd.conf: |
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    dial-timeout: 10000000000
    allow-delayed-start: true
    endpoints:
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"

---

# This config map contains ETCD configuration for connecting to the contiv-etcd defined above with auto comapact.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-withcompact-cfg
  namespace: kube-system
data:
  etcd.conf: |
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    dial-timeout: 10000000000
    auto-compact: 600000000000
    allow-delayed-start: true
    reconnect-interval: 2000000000
    endpoints:
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"

{{- if .Values.http.enableServerCert }}
{{- if not .Values.http.mountFromHost }}
---

# The following contains k8s Secrets for use with a secured HTTP plugin.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-http-secrets
  namespace: kube-system
data:
  serverCert: |-
    {{ .Files.Get .Values.http.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.http.serverKey | b64enc }}
{{- end }}
{{- end }}

---

# This installs contiv-vswitch on each master and worker node in a Kubernetes cluster.
# It consists of the following containers:
#   - contiv-vswitch container: contains VPP and its management agent
#   - contiv-cni container: installs CNI on the host
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: contiv-vswitch
  namespace: kube-system
  labels:
    k8s-app: contiv-vswitch
spec:
  selector:
    matchLabels:
      k8s-app: contiv-vswitch
  updateStrategy:
    type: {{ .Values.vswitch.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-vswitch
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      hostNetwork: true
      hostPID: true

      # Init containers are executed before regular containers, must finish successfully before regular ones are started.
      initContainers:
        # This container installs the Contiv CNI binaries and CNI network config file on each node.
        - name: contiv-cni
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.cni_arm64.image.repository }}:{{ .Values.cni.image.tag }}
          {{- else }}
          image: {{ .Values.cni.image.repository }}:{{ .Values.cni.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          env:
            - name: SLEEP
              value: "false"
          volumeMounts:
            - mountPath: /opt/cni/bin
              name: cni-bin-dir
            - mountPath: /etc/cni/net.d
              name: cni-net-dir
            - mountPath: /var/run/contiv
              name: contiv-run

        {{- if eq .Values.contiv.crdNodeConfigurationDisabled false }}
        # This init container waits until crd node specific configuration has been applied
        - name: wait-forcrdconfig
          env:
          - name: ETCDPORT
            value: "32379"
          - name: ETCDCTL_API
            value: "3"
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.etcd_arm64.image.repository }}:{{ .Values.etcd_arm64.image.tag }}
          {{- else }}
          image: {{ .Values.etcd.image.repository }}:{{ .Values.etcd.image.tag }}
          {{- end }}
          command:
          - /bin/sh
          args:
          - -c
          - |
            set -eu
          {{- if .Values.etcd.secureTransport }}
            until /usr/local/bin/etcdctl --endpoints=127.0.0.1:$ETCDPORT get "/vnf-agent/contiv-ksr/k8s/nodeconfig/$HOSTNAME" --prefix=true \
            --cert=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }} --key=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }} --cacert=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}| grep -m 1 "$HOSTNAME";
          {{- else }}
            until /usr/local/bin/etcdctl --endpoints=127.0.0.1:$ETCDPORT get "/vnf-agent/contiv-ksr/k8s/nodeconfig/$HOSTNAME" --prefix=true | grep -m 1 "$HOSTNAME";
          {{- end }}
            do
              echo waiting for crd node config;
              sleep 1
            done
          {{- if .Values.etcd.secureTransport }}
          volumeMounts:
          - name: etcd-secrets
            mountPath: /var/contiv/etcd-secrets
            readOnly: true
          {{- end }}
        {{- end }}

        # This init container extracts/copies default VPP config to the host and initializes VPP core dumps.
        - name: vpp-init
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.vswitch_arm64.image.repository }}:{{ .Values.vswitch.image.tag }}
          {{- else }}
          image: {{ .Values.vswitch.image.repository }}:{{ .Values.vswitch.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
          command:
            - /bin/sh
          args:
            - -c
            - |
              set -eu
              chmod 700 /run/vpp
              rm -rf /dev/shm/db /dev/shm/global_vm /dev/shm/vpe-api
              if [ ! -e /host/etc/vpp/contiv-vswitch.conf ]; then
                  cp /etc/vpp/contiv-vswitch.conf /host/etc/vpp/
              fi
              if [ ! -d /var/run/contiv ]; then
                  mkdir /var/run/contiv
              fi
              chmod 700 /var/run/contiv
              rm -f /var/run/contiv/cni.sock
              if ip link show vpp1 >/dev/null 2>&1; then
                   ip link del vpp1
              fi
              cp -f /usr/local/bin/vppctl /host/usr/local/bin/vppctl
              {{- if .Values.vswitch.enableCoreDumps }}
              sysctl -w debug.exception-trace=1
              sysctl -w kernel.core_pattern="{{ .Values.vswitch.coreDumpsDir }}/%e-%t"
              ulimit -c unlimited
              echo 2 > /proc/sys/fs/suid_dumpable
              {{- end }}
          resources: {}
          securityContext:
            privileged: true
          volumeMounts:
            - name: usr-local-bin
              mountPath: /host/usr/local/bin
            - name: vpp-cfg
              mountPath: /host/etc/vpp
            - name: shm
              mountPath: /dev/shm
            - name: vpp-run
              mountPath: /run/vpp
            - name: contiv-run
              mountPath: /var/run/contiv
            {{- if .Values.vswitch.enableCoreDumps }}
            - name: core-dumps
              mountPath: {{ .Values.vswitch.coreDumpsDir }}
            {{- end }}

      containers:
        # Runs contiv-vswitch container on each Kubernetes node.
        # It contains the vSwitch VPP and its management agent.
        - name: contiv-vswitch
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.vswitch_arm64.image.repository }}:{{ .Values.vswitch.image.tag }}
          {{- else }}
          image: {{ .Values.vswitch.image.repository }}:{{ .Values.vswitch.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
          securityContext:
            privileged: true
          ports:
            # readiness + liveness probe
            - containerPort: 9999
          {{- if .Values.vswitch.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9999
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.vswitch.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.vswitch.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.vswitch.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.vswitch.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9999
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.vswitch.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.vswitch.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.vswitch.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.vswitch.livenessProbeInitialDelaySeconds }}
          {{- end }}
          env:
            - name: MICROSERVICE_LABEL
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CONTIV_CONFIG
              value: "/etc/contiv/contiv.conf"
            - name: CONTROLLER_CONFIG
              value: "/etc/contiv/controller.conf"
            - name: SERVICE_CONFIG
              value: "/etc/contiv/service.conf"
            - name: ETCD_CONFIG
              value: "/etc/etcd/etcd.conf"
            - name: BOLT_CONFIG
              value: "/etc/vpp-agent/bolt.conf"
            {{- if .Values.bolt.debug }}
            - name: DEBUG_BOLT_CLIENT
              value: "true"
            {{- end}}
            - name: TELEMETRY_CONFIG
              value: "/etc/vpp-agent/telemetry.conf"
            - name: GOVPP_CONFIG
              value: "/etc/vpp-agent/govpp.conf"
            - name: LOGS_CONFIG
              value: "/etc/vpp-agent/logs.conf"
            - name: HTTP_CONFIG
              value: "/etc/vpp-agent/http.conf"
            - name: GRPC_CONFIG
              value: "/etc/vpp-agent/grpc.conf"
            - name: LINUX_IFPLUGIN_CONFIG
              value: "/etc/vpp-agent/linux-ifplugin.conf"
            - name: LINUX_L3PLUGIN_CONFIG
              value: "/etc/vpp-agent/linux-l3plugin.conf"
            - name: KVSCHEDULER_CONFIG
              value: "/etc/vpp-agent/kvscheduler.conf"
          volumeMounts:
            - name: var-bolt
              mountPath: /var/bolt
            - name: etcd-cfg
              mountPath: /etc/etcd
              {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
              {{- end }}
              {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
              {{- end }}
            - name: vpp-cfg
              mountPath: /etc/vpp
            - name: shm
              mountPath: /dev/shm
            - name: dev
              mountPath: /dev
            - name: sys-bus-pci
              mountPath: /sys/bus/pci
            - name: vpp-run
              mountPath: /run/vpp
            - name: contiv-run
              mountPath: /var/run/contiv
            - name: contiv-agent-cfg
              mountPath: /etc/contiv
            - name: vpp-agent-cfg
              mountPath: /etc/vpp-agent
            - name: tmp
              mountPath: /tmp
            {{- if .Values.vswitch.enableCoreDumps }}
            - name: core-dumps
              mountPath: {{ .Values.vswitch.coreDumpsDir }}
            {{- end }}
            - name: docker-socket
              mountPath: /var/run/docker.sock
          resources:
            {{- if or .Values.vswitch.defineMemoryLimits .Values.vswitch.cpuLimit }}
            limits:
            {{- end }}
            {{- if .Values.vswitch.defineMemoryLimits }}
              {{- if .Values.vswitch.hugePages1giLimit }}
              hugepages-1Gi: {{ .Values.vswitch.hugePages1giLimit }}
              {{- else }}
                {{- if .Values.vswitch.hugePages2miLimit }}
              hugepages-2Mi: {{ .Values.vswitch.hugePages2miLimit }}
                {{- end }}
              {{- end }}
              memory: {{ .Values.vswitch.memoryLimit }}
            {{- end }}
            {{- if .Values.vswitch.cpuLimit }}
              cpu: {{ .Values.vswitch.cpuLimit }}
            {{- end }}
            {{- if .Values.vswitch.cpuRequest }}
            requests:
              cpu: {{ .Values.vswitch.cpuRequest }}
            {{- end }}

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-cfg
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # VPP startup config folder.
        - name: vpp-cfg
          hostPath:
            path: /etc/vpp
        # To install vppctl.
        - name: usr-local-bin
          hostPath:
            path: /usr/local/bin
        # /dev mount is required for DPDK-managed NICs on VPP (/dev/uio0) and for shared memory communication with VPP (/dev/shm)
        - name: dev
          hostPath:
            path: /dev
        - name: shm
          hostPath:
            path: /dev/shm
        # /sys/bus/pci is required for binding PCI devices to specific drivers
        - name: sys-bus-pci
          hostPath:
            path: /sys/bus/pci
        # For CLI unix socket.
        - name: vpp-run
          hostPath:
            path: /run/vpp
        # For CNI / STN unix domain socket
        - name: contiv-run
          hostPath:
            path: /var/run/contiv
        # Used to configure contiv agent.
        - name: contiv-agent-cfg
          configMap:
            name: contiv-agent-cfg
        # Used to configure vpp agent.
        - name: vpp-agent-cfg
          configMap:
            name: vpp-agent-cfg
        {{- if .Values.vswitch.enableCoreDumps }}
        # Used for vswitch core dumps
        - name: core-dumps
          hostPath:
            path: {{ .Values.vswitch.coreDumpsDir }}
        {{- end }}
        # /tmp in the vswitch container (needs to be persistent between container restarts to obtain post-mortem files)
        - name: tmp
          emptyDir:
            medium: Memory
        # persisted bolt data
        - name: var-bolt
          hostPath:
            path: {{ .Values.bolt.dataDir }}
        - name: docker-socket
          hostPath:
            path: /var/run/docker.sock

---

# This installs the contiv-ksr (Kubernetes State Reflector) on the master node in a Kubernetes cluster.
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: contiv-ksr
  namespace: kube-system
  labels:
    k8s-app: contiv-ksr
spec:
  updateStrategy:
    type: {{ .Values.ksr.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-ksr
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true
      # This grants the required permissions to contiv-ksr.
      serviceAccountName: contiv-ksr

      initContainers:
        # This init container waits until etcd is started
        - name: wait-foretcd
          env:
            - name: ETCDPORT
              value: {{ .Values.etcd.service.nodePort | quote }}
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.init_arm64.image.repository }}:{{ .Values.init.image.tag }}
          {{- else }}
          image: {{ .Values.init.image.repository }}:{{ .Values.init.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          command: ['sh', '-c', 'until nc -w 2 127.0.0.1:$ETCDPORT; do echo waiting for etcd; sleep 2; done;']

      containers:
        - name: contiv-ksr
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.ksr_arm64.image.repository }}:{{ .Values.ksr.image.tag }}
          {{- else }}
          image: {{ .Values.ksr.image.repository }}:{{ .Values.ksr.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.ksr.image.pullPolicy }}
          env:
            - name: ETCD_CONFIG
              value: "/etc/etcd/etcd.conf"
            - name: HTTP_CONFIG
              value: "/etc/http/http.conf"
          volumeMounts:
            - name: etcd-cfg
              mountPath: /etc/etcd
            - name: http-cfg
              mountPath: /etc/http
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
            {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
            {{- end }}
          {{- if .Values.ksr.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9191
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.ksr.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.ksr.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.ksr.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.ksr.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9191
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.ksr.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.ksr.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.ksr.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.ksr.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.ksr.cpuLimit }}
            limits:
              cpu: {{ .Values.ksr.cpuLimit }}
            {{- end }}
            {{- if .Values.ksr.cpuRequest }}
            requests:
              cpu: {{ .Values.ksr.cpuRequest }}
            {{- end }}
      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-withcompact-cfg
        - name: http-cfg
          configMap:
            name: contiv-ksr-http-cfg
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}

---

# This cluster role defines a set of permissions required for contiv-ksr.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: contiv-ksr
  namespace: kube-system
rules:
  - apiGroups:
      - ""
      - extensions
    resources:
      - pods
      - namespaces
      - networkpolicies
      - services
      - endpoints
      - nodes
    verbs:
      - watch
      - list

---

# This defines a service account for contiv-ksr.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-ksr
  namespace: kube-system

---

# This binds the contiv-ksr cluster role with contiv-ksr service account.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-ksr
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-ksr
subjects:
  - kind: ServiceAccount
    name: contiv-ksr
    namespace: kube-system

---

# This installs the contiv-crd on the master node in a Kubernetes cluster.
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: contiv-crd
  namespace: kube-system
  labels:
    k8s-app: contiv-crd
spec:
  updateStrategy:
    type: {{ .Values.crd.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-crd
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true
      # This grants the required permissions to contiv-crd.
      serviceAccountName: contiv-crd

      initContainers:
        # This init container waits until etcd is started
        - name: wait-foretcd
          env:
            - name: ETCDPORT
              value: {{ .Values.etcd.service.nodePort | quote }}
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.init_arm64.image.repository }}:{{ .Values.init.image.tag }}
          {{- else }}
          image: {{ .Values.init.image.repository }}:{{ .Values.init.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          command: ['sh', '-c', 'until nc -w 2 127.0.0.1:$ETCDPORT; do echo waiting for etcd; sleep 2; done;']

        # This init container copies contiv-netctl tool to the host.
        - name: netctl-init
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.crd_arm64.image.repository }}:{{ .Values.crd.image.tag }}
          {{- else }}
          image: {{ .Values.crd.image.repository }}:{{ .Values.crd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.crd.image.pullPolicy }}
          command:
            - /bin/sh
          args:
            - -c
            - |
              echo '#!/bin/sh
              kubectl get pods -n kube-system | \
                grep contiv-crd | \
                cut -d " " -f 1 | \
                xargs -I{} kubectl exec -n kube-system {} \
                /contiv-netctl "$@"' \
              > /host/usr/local/bin/contiv-netctl || true
              chmod +x /host/usr/local/bin/contiv-netctl || true
          volumeMounts:
            - name: usr-local-bin
              mountPath: /host/usr/local/bin

      containers:
        - name: contiv-crd
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.crd_arm64.image.repository }}:{{ .Values.crd.image.tag }}
          {{- else }}
          image: {{ .Values.crd.image.repository }}:{{ .Values.crd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.crd.image.pullPolicy }}
          env:
            - name: ETCD_CONFIG
              value: "/etc/etcd/etcd.conf"
            - name: HTTP_CONFIG
              value: "/etc/http/http.conf"
            - name: HTTP_CLIENT_CONFIG
              value: "/etc/http/http.client.conf"
            - name: CONTIV_CRD_VALIDATE_INTERVAL
              value: {{ .Values.crd.validateInterval | quote }}
            - name: CONTIV_CRD_VALIDATE_STATE
              value: {{ .Values.crd.validateState | quote }}
          volumeMounts:
            - name: etcd-cfg
              mountPath: /etc/etcd
            - name: http-cfg
              mountPath: /etc/http
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
            {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
            {{- end }}
            {{- if .Values.crd.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9090
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.crd.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.crd.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.crd.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.crd.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9090
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.crd.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.crd.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.crd.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.crd.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.crd.cpuLimit }}
            limits:
              cpu: {{ .Values.crd.cpuLimit }}
            {{- end }}
            {{- if .Values.crd.cpuRequest }}
            requests:
              cpu: {{ .Values.crd.cpuRequest }}
            {{- end }}

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-cfg
        - name: usr-local-bin
          hostPath:
            path: /usr/local/bin
        - name: http-cfg
          configMap:
            name: contiv-crd-http-cfg
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}
---

# This cluster role defines a set of permissions required for contiv-crd.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: contiv-crd
  namespace: kube-system
rules:
  - apiGroups:
      - apiextensions.k8s.io
      - nodeconfig.contiv.vpp
      - telemetry.contiv.vpp
    resources:
      - customresourcedefinitions
      - telemetryreports
      - nodeconfigs
    verbs:
      - "*"

---

# This defines a service account for contiv-crd.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-crd
  namespace: kube-system

---

# This binds the contiv-crd cluster role with contiv-crd service account.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-crd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-crd
subjects:
  - kind: ServiceAccount
    name: contiv-crd
    namespace: kube-system

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-crd-http-cfg
  namespace: kube-system
data:
  http.conf: |
    endpoint: 0.0.0.0:9090
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}
  http.client.conf: |
    port: 9999
    {{- if .Values.http.enableBasicAuth }}
    basic-auth: {{ .Values.http.basicAuth | quote }}
    {{- end }}
    use-https: {{ .Values.http.enableServerCert }}