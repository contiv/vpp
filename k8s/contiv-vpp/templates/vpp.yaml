# Contiv-VPP deployment YAML file. This deploys Contiv VPP networking on a Kuberntes cluster.
# The deployment consists of the following components:
#   - contiv-etcd - deployed on k8s master
#   - contiv-vswitch - deployed on each k8s node
#   - contiv-ksr - deployed on k8s master

{{- if contains ":" .Values.contiv.ipamConfig.podSubnetCIDR }}
  {{- $ignored := set . "any_addr_tmp" "[::]" }}
  {{- $ignored := set . "localhost_addr_tmp" "[::1]" }}
{{- else }}
  {{- $ignored := set . "any_addr_tmp" "0.0.0.0" }}
  {{- $ignored := set . "localhost_addr_tmp" "127.0.0.1" }}
{{- end }}

{{- $any_addr := .any_addr_tmp -}}
{{- $localhost_addr := .localhost_addr_tmp }}

###########################################################
#  Configuration
###########################################################

# This config map contains contiv-agent configuration. The most important part is the ipamConfig,
# which may be updated in case the default IPAM settings do not match your needs.
# nodeConfig may be used in case your nodes have more than 1 VPP interface. In that case, one
# of them needs to be marked as the main inter-node interface, and the rest of them can be
# configured with any IP addresses (the IPs cannot conflict with the main IPAM config).
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-agent-cfg
  namespace: kube-system
data:
  contiv.conf: |-
    nodeToNodeTransport: {{ .Values.contiv.nodeToNodeTransport }}
    useSRv6ForServices: {{ .Values.contiv.useSRv6ForServices }}
    useSRv6ForServiceFunctionChaining: {{ .Values.contiv.useSRv6ForServiceFunctionChaining}}
    useDX6ForSrv6NodetoNodeTransport: {{ .Values.contiv.useDX6ForSrv6NodetoNodeTransport }}
    useTAPInterfaces: {{ .Values.contiv.useTAPInterfaces }}
    tapInterfaceVersion: {{ .Values.contiv.tapInterfaceVersion }}
    {{- if eq (.Values.contiv.tapInterfaceVersion | int) 2 }}
    tapv2RxRingSize: {{ .Values.contiv.tapv2RxRingSize }}
    tapv2TxRingSize: {{ .Values.contiv.tapv2TxRingSize }}
    enableGSO: {{ .Values.contiv.enableGSO }}
    {{- end }}
    {{- if ne (.Values.contiv.vmxnet3RxRingSize | int) 1024 }}
    vmxnet3RxRingSize: {{ .Values.contiv.vmxnet3RxRingSize }}
    {{- end }}
    {{- if ne (.Values.contiv.vmxnet3TxRingSize | int) 1024 }}
    vmxnet3TxRingSize: {{ .Values.contiv.vmxnet3TxRingSize }}
    {{- end }}
    {{- if ne .Values.contiv.interfaceRxMode "default" }}
    interfaceRxMode: {{ .Values.contiv.interfaceRxMode }}
    {{- end }}
    tcpChecksumOffloadDisabled: true
    {{- if .Values.contiv.stealInterface }}
    stealInterface: {{ .Values.contiv.stealInterface }}
    {{- end }}
    {{- if .Values.contiv.stealFirstNIC }}
    stealFirstNIC: True
    {{- end }}
    STNVersion: {{ .Values.contiv.stnVersion }}
    natExternalTraffic: {{ .Values.contiv.natExternalTraffic }}
    mtuSize: {{ .Values.contiv.mtuSize }}
    scanIPNeighbors: {{ .Values.contiv.scanIPNeighbors }}
    ipNeighborScanInterval: {{ .Values.contiv.ipNeighborScanInterval }}
    ipNeighborStaleThreshold: {{ .Values.contiv.ipNeighborStaleThreshold }}
    enablePacketTrace: {{ .Values.contiv.enablePacketTrace }}
    routeServiceCIDRToVPP: {{ .Values.contiv.routeServiceCIDRToVPP }}
    crdNodeConfigurationDisabled: {{ .Values.contiv.crdNodeConfigurationDisabled }}
    ipamConfig:
      {{- if .Values.contiv.ipamConfig.useExternalIPAM }}
      useExternalIPAM: true
      {{- end }}
      {{- if .Values.contiv.ipamConfig.contivCIDR }}
      contivCIDR: {{ .Values.contiv.ipamConfig.contivCIDR }}
      {{- else }}
      nodeInterconnectDHCP: {{ .Values.contiv.ipamConfig.nodeInterconnectDHCP }}
      {{- if .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      nodeInterconnectCIDR: {{ .Values.contiv.ipamConfig.nodeInterconnectCIDR }}
      {{- end }}
      {{- if .Values.contiv.ipamConfig.defaultGateway }}
      defaultGateway: {{ .Values.contiv.ipamConfig.defaultGateway }}
      {{- end }}
      podSubnetCIDR: {{ .Values.contiv.ipamConfig.podSubnetCIDR }}
      podSubnetOneNodePrefixLen: {{ .Values.contiv.ipamConfig.podSubnetOneNodePrefixLen }}
      vppHostSubnetCIDR: {{ .Values.contiv.ipamConfig.vppHostSubnetCIDR }}
      vppHostSubnetOneNodePrefixLen: {{ .Values.contiv.ipamConfig.vppHostSubnetOneNodePrefixLen }}
      vxlanCIDR: {{ .Values.contiv.ipamConfig.vxlanCIDR }}
      {{- end }}
      {{- if .Values.contiv.ipamConfig.serviceCIDR }}
      serviceCIDR: {{ .Values.contiv.ipamConfig.serviceCIDR }}
      {{- end }}
      srv6:
        servicePolicyBSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.servicePolicyBSIDSubnetCIDR }}
        servicePodLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.servicePodLocalSIDSubnetCIDR }}
        serviceHostLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.serviceHostLocalSIDSubnetCIDR }}
        serviceNodeLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.serviceNodeLocalSIDSubnetCIDR }}
        nodeToNodePodLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.nodeToNodePodLocalSIDSubnetCIDR }}
        nodeToNodeHostLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.nodeToNodeHostLocalSIDSubnetCIDR }}
        nodeToNodePodPolicySIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.nodeToNodePodPolicySIDSubnetCIDR }}
        nodeToNodeHostPolicySIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.nodeToNodeHostPolicySIDSubnetCIDR }}
        sfcPolicyBSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.sfcPolicyBSIDSubnetCIDR}}
        sfcServiceFunctionSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.sfcServiceFunctionSIDSubnetCIDR}}
        sfcEndLocalSIDSubnetCIDR: {{ .Values.contiv.ipamConfig.srv6.sfcEndLocalSIDSubnetCIDR}}
        sfcIDLengthUsedInSidForServiceFunction: {{ .Values.contiv.ipamConfig.srv6.sfcIDLengthUsedInSidForServiceFunction}}
    {{- if .Values.contiv.nodeConfig }}
    nodeConfig:
    {{- range .Values.contiv.nodeConfig }}
    - nodeName: {{ .name }}
      mainVPPInterface:
        interfaceName: {{ .mainInterface.interfaceName }}
        {{- if .mainInterface.useDHCP }}
        useDHCP: {{ .mainInterface.useDHCP }}
        {{- end -}}
        {{- if .mainInterface.ip }}
        ip: {{ .mainInterface.ip }}
        {{- end -}}
      {{- if .natExternalTraffic }}
      natExternalTraffic: {{ .natExternalTraffic }}
      {{- end }}
      {{- if .gateway }}
      gateway: {{ .gateway }}
      {{- end -}}
      {{- if .stealInterface }}
      stealInterface: {{ .stealInterface }}
      {{- end -}}
      {{- if .otherInterfaces }}
      otherVPPInterfaces:
      {{- range $iface := .otherInterfaces }}
        - interfaceName: {{ $iface.interfaceName }}
          ip: {{ $iface.ip }}
      {{- end }}
      {{- end }}
    {{- end }}
    {{- end }}
  controller.conf: |
    enableRetry: {{ .Values.controller.enableRetry }}
    delayRetry: {{ .Values.controller.delayRetry | int64 }}
    maxRetryAttempts: {{ .Values.controller.maxRetryAttempts }}
    enableExpBackoffRetry: {{ .Values.controller.enableExpBackoffRetry }}
    delayLocalResync: {{ .Values.controller.delayLocalResync | int64 }}
    startupResyncDeadline: {{ .Values.controller.startupResyncDeadline | int64 }}
    enablePeriodicHealing: {{ .Values.controller.enablePeriodicHealing }}
    periodicHealingInterval: {{ .Values.controller.periodicHealingInterval | int64 }}
    delayAfterErrorHealing: {{ .Values.controller.delayAfterErrorHealing | int64 }}
    remoteDBProbingInterval: {{ .Values.controller.remoteDBProbingInterval | int64 }}
    recordEventHistory: {{ .Values.controller.recordEventHistory }}
    eventHistoryAgeLimit: {{ .Values.controller.eventHistoryAgeLimit }}
    permanentlyRecordedInitPeriod: {{ .Values.controller.permanentlyRecordedInitPeriod }}
  service.conf: |
    {{- if .Values.contiv.cleanupIdleNATSessions }}
    cleanupIdleNATSessions: true
    tcpNATSessionTimeout: {{ .Values.contiv.tcpNATSessionTimeout }}
    otherNATSessionTimeout: {{ .Values.contiv.otherNATSessionTimeout }}
    {{- end }}
    {{- if .Values.contiv.serviceLocalEndpointWeight }}
    serviceLocalEndpointWeight: {{ .Values.contiv.serviceLocalEndpointWeight }}
    {{- end }}
    disableNATVirtualReassembly: {{ .Values.contiv.disableNATVirtualReassembly }}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: vpp-agent-cfg
  namespace: kube-system
data:
  govpp.conf: |
    health-check-probe-interval: {{ .Values.govpp.healthCheckProbeInterval | int64 }}
    health-check-reply-timeout: {{ .Values.govpp.healthCheckReplyTimeout | int64 }}
    health-check-threshold: {{ .Values.govpp.healthCheckThreshold | int64 }}
    reply-timeout: {{ .Values.govpp.replyTimeout | int64 }}
  logs.conf: |
    default-level: {{ .Values.logs.defaultLevel }}
    loggers:
      - name: statscollector
        level: info
      - name: vpp.if-state
        level: info
      - name: linux.arp-conf
        level: info
      - name: vpp-rest
        level: info
  # GRPC server used to accept CNI Add/Del Pod requests
  grpc.conf: |
    network: unix
    endpoint: /var/run/contiv/cni.sock
    force-socket-removal: true
    permission: 700
  # GRCP server used to accept additional network configuration
  grpc2.conf: |
    endpoint: "{{ $any_addr }}:{{ .Values.vswitch.grpcPort }}"
  http.conf: |
    endpoint: "{{ $any_addr }}:{{ .Values.vswitch.httpPort }}"
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}
  bolt.conf: |
    db-path: /var/bolt/bolt.db
    file-mode: 432
    lock-timeout: 0
  telemetry.conf: |
    polling-interval: {{ .Values.telemetry.pollingInterval | int64 }}
    disabled: {{ .Values.telemetry.disabled }}
  linux-ifplugin.conf: |
    dump-go-routines-count: 5
  linux-l3plugin.conf: |
    dump-go-routines-count: 5
  kvscheduler.conf: |
    record-transaction-history: {{ .Values.controller.recordEventHistory }}
    transaction-history-age-limit: {{ .Values.controller.eventHistoryAgeLimit }}
    permanently-recorded-init-period: {{ .Values.controller.permanentlyRecordedInitPeriod }}

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: contiv-cni-cfg
  namespace: kube-system
data:
  # The CNI network configuration to install on each node. The special
  # values in this config will be automatically populated.
  10-contiv-vpp.conflist: |-
    {
      "name": "k8s-pod-network",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "contiv-cni",
          "grpcServer": "/var/run/contiv/cni.sock",
          {{- if .Values.contiv.ipamConfig.useExternalIPAM }}
          "ipam": {
            "type": "host-local",
            "subnet": "usePodCidr"
          },
          "etcdEndpoints" : "{{ $localhost_addr }}:{{ .Values.etcd.service.nodePort }}",
          {{- end }}
          "logFile": "/var/run/contiv/cni.log"
        },
        {
          "type": "portmap",
          "capabilities": {
              "portMappings": true
          },
          "externalSetMarkChain": "KUBE-MARK-MASQ"
        }
      ]
    }
---

###########################################################
#
# !!! DO NOT EDIT THINGS BELOW THIS LINE !!!
#
###########################################################


###########################################################
#  Components and other resources
###########################################################

# This installs the contiv-etcd (ETCD server to be used by Contiv) on the master node in a Kubernetes cluster.
# In odrer to dump the content of ETCD, you can use the kubectl exec command similar to this:
#   kubectl exec contiv-etcd-cxqhr -n kube-system etcdctl -- get --endpoints=[127.0.0.1:12379] --prefix="true" ""
{{- define "utils.commaseparated" -}}
{{- $local := dict "first" true -}}
{{- range $k, $v := . -}}{{- if not $local.first -}},{{- end -}}{{- $v -}}{{- $_ := set $local "first" false -}}{{- end -}}
{{- end }}
{{- if not .Values.etcd.useExternalInstance }}
{{- if .Values.k8sVersion.post_1_9 }}
apiVersion: apps/v1
{{- else }}
apiVersion: apps/v1beta2
{{- end }}
kind: StatefulSet
metadata:
  name: contiv-etcd
  namespace: kube-system
  labels:
    k8s-app: contiv-etcd
spec:
  serviceName: contiv-etcd
  selector:
    matchLabels:
      k8s-app: contiv-etcd
  updateStrategy:
    type: {{ .Values.etcd.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-etcd
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true

      containers:
        - name: contiv-etcd
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.etcd_arm64.image.repository }}:{{ .Values.etcd_arm64.image.tag }}
          {{- else }}
          image: {{ .Values.etcd.image.repository }}:{{ .Values.etcd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.etcd.image.pullPolicy }}
          env:
            - name: CONTIV_ETCD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HOST_IP
            {{- if .Values.etcd.service.useNodeIP }}
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            {{- else }}
              value: "127.0.0.1"
            {{- end }}
            - name: ETCDCTL_API
              value: "3"
            {{- if .Values.Arm64Platform }}
            - name: ETCD_UNSUPPORTED_ARCH
              value: "arm64"
            {{- end }}
            {{- if .Values.etcd.secureTransport }}
            - name: ETCDCTL_CACERT
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
            - name: ETCDCTL_CERT
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
            - name: ETCDCTL_KEY
              value: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
            {{- end }}
          command:
            - /bin/sh
          args:
            - -c
            - /usr/local/bin/etcd --name=contiv-etcd --data-dir=/var/etcd/contiv-data
            {{- if .Values.etcd.secureTransport }}
              --client-cert-auth --trusted-ca-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
              --cert-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverCert }} --key-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverKey }}
              --peer-client-cert-auth --peer-trusted-ca-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
              --peer-cert-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverCert }} --peer-key-file=/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.serverKey }}
              --advertise-client-urls=https://{{ $any_addr }}:12379 --listen-client-urls=https://{{ $any_addr }}:12379 --listen-peer-urls=https://{{ $any_addr }}:12380
              {{- if .Values.etcd.cipherSuites }}
              --cipher-suites {{ include "utils.commaseparated" .Values.etcd.cipherSuites }}
              {{- end }}
            {{- else }}
              --advertise-client-urls=http://{{ $any_addr }}:12379 --listen-client-urls=http://{{ $any_addr }}:12379 --listen-peer-urls=http://{{ $any_addr }}:12380
            {{- end }}
          volumeMounts:
            - name: var-etcd
              mountPath: /var/etcd/
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
          {{- if .Values.etcd.enableLivenessProbe }}
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - |
                  echo "$HOST_IP" | grep -q ':'
                  if [ "$?" -eq "0" ];
                  then
                     HOST_IP="[$HOST_IP]"
                  fi
                  etcdctl get --endpoints=$HOST_IP:{{ .Values.etcd.service.nodePort }} /
            periodSeconds: {{ .Values.etcd.probePeriodSeconds }}
            initialDelaySeconds: {{ .Values.etcd.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.etcd.cpuLimit }}
            limits:
              cpu: {{ .Values.etcd.cpuLimit }}
            {{- end }}
            {{- if .Values.etcd.cpuRequest }}
            requests:
              cpu: {{ .Values.etcd.cpuRequest }}
            {{- end }}
      {{- if .Values.etcd.secureTransport }}
      volumes:
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: serverCert
              path: {{ .Values.etcd.secrets.serverCert }}
            - key: serverKey
              path: {{ .Values.etcd.secrets.serverKey }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
      {{- end }}
{{- if .Values.etcd.usePersistentVolume }}
  volumeClaimTemplates:
  - metadata:
      name: var-etcd
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.etcd.persistentVolumeSize }}
    {{- if .Values.etcd.persistentVolumeStorageClass }}
    {{- if (eq "-" .Values.etcd.persistentVolumeStorageClass) }}
      storageClassName: ""
    {{- else }}
      storageClassName: "{{ .Values.etcd.persistentVolumeStorageClass }}"
    {{- end }}
    {{- end }}
{{- else }}
      {{- if not .Values.etcd.secureTransport }}
      volumes:
      {{- end }}
        - name: var-etcd
          hostPath:
            path: {{ .Values.etcd.dataDir }}
{{- end }}


{{- if .Values.etcd.secureTransport }}
{{- if not .Values.etcd.secrets.mountFromHost }}
---

# The following contains k8s Secrets for use with a TLS enabled etcd cluster.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-etcd-secrets
  namespace: kube-system
data:
  caCert: |-
    {{ .Files.Get .Values.etcd.secrets.caCert | b64enc }}
  serverCert: |-
    {{ .Files.Get .Values.etcd.secrets.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.etcd.secrets.serverKey | b64enc }}
  clientCert: |-
    {{ .Files.Get .Values.etcd.secrets.clientCert | b64enc }}
  clientKey: |-
    {{ .Files.Get .Values.etcd.secrets.clientKey | b64enc }}
{{- end }}
{{- end }}

---

apiVersion: v1
kind: Service
metadata:
  name: contiv-etcd
  namespace: kube-system
spec:
  type: NodePort
  # Match contiv-etcd DaemonSet.
  selector:
    k8s-app: contiv-etcd
  ports:
    - port: 12379
      nodePort: {{ .Values.etcd.service.nodePort }}
{{- end }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-ksr-http-cfg
  namespace: kube-system
data:
  http.conf: |
    endpoint: "{{ $any_addr }}:{{ .Values.ksr.httpPort }}"
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}

---
# This config map contains ETCD configuration for connecting to the contiv-etcd defined above.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-cfg
  namespace: kube-system
data:
  etcd.conf: |
    dial-timeout: 10000000000
    allow-delayed-start: true
    {{- if .Values.etcd.useExternalInstance }}
      {{- if .Values.etcd.externalInstance.secretName }}
    insecure-transport: false
    ca-file: /var/contiv/etcd-secrets/caCert
    cert-file: /var/contiv/etcd-secrets/clientCert
    key-file: /var/contiv/etcd-secrets/clientKey
      {{- else }}
    insecure-transport: true
      {{- end }}
    endpoints:
      {{- range .Values.etcd.externalInstance.endpoints }}
      - {{ . | quote }}
      {{- end }}
    {{- else }}
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    endpoints:
      {{- if .Values.etcd.service.useNodeIP }}
      - "__HOST_IP__:{{ .Values.etcd.service.nodePort }}"
      {{- else }}
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"
      {{- end }}
    {{- end }}

---
{{- if not .Values.etcd.useExternalInstance }}

# This config map contains ETCD configuration for connecting to the contiv-etcd defined above with auto compact.
apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-etcd-withcompact-cfg
  namespace: kube-system
data:
  etcd.conf: |
    {{- if .Values.etcd.secureTransport }}
    insecure-transport: false
    ca-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}
    cert-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}
    key-file: /var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}
    {{- else }}
    insecure-transport: true
    {{- end }}
    dial-timeout: 10000000000
    auto-compact: 600000000000
    allow-delayed-start: true
    reconnect-interval: 2000000000
    endpoints:
    {{- if .Values.etcd.service.useNodeIP }}
      - "__HOST_IP__:{{ .Values.etcd.service.nodePort }}"
    {{- else }}
      - "127.0.0.1:{{ .Values.etcd.service.nodePort }}"
    {{- end }}

{{- if .Values.http.enableServerCert }}
{{- if not .Values.http.mountFromHost }}
---
{{- end }} # end of if useExternalETCDinstance

# The following contains k8s Secrets for use with a secured HTTP plugin.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: contiv-http-secrets
  namespace: kube-system
data:
  serverCert: |-
    {{ .Files.Get .Values.http.serverCert | b64enc }}
  serverKey: |-
    {{ .Files.Get .Values.http.serverKey | b64enc }}
{{- end }}
{{- end }}

---

# This installs contiv-vswitch on each master and worker node in a Kubernetes cluster.
# It consists of the following containers:
#   - contiv-vswitch container: contains VPP and its management agent
#   - contiv-cni container: installs CNI on the host
{{- if .Values.k8sVersion.post_1_9 }}
apiVersion: apps/v1
{{- else }}
apiVersion: extensions/v1beta1
{{- end }}
kind: DaemonSet
metadata:
  name: contiv-vswitch
  namespace: kube-system
  labels:
    k8s-app: contiv-vswitch
spec:
  selector:
    matchLabels:
      k8s-app: contiv-vswitch
  updateStrategy:
    type: {{ .Values.vswitch.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-vswitch
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      {{- if .Values.vswitch.useNodeAffinity }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cni-type
                operator: In
                values:
                  - vpp
      {{- end }}
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      hostNetwork: true
      hostPID: true

      # Init containers are executed before regular containers, must finish successfully before regular ones are started.
      initContainers:
        # This container installs the Contiv CNI binaries and CNI network config file on each node.
        - name: contiv-cni
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.cni_arm64.image.repository }}:{{ default .Chart.Version .Values.cni.image.tag }}
          {{- else }}
          image: {{ .Values.cni.image.repository }}:{{ default .Chart.Version .Values.cni.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          env:
            - name: SLEEP
              value: "false"
          volumeMounts:
            - mountPath: /opt/cni/bin
              name: cni-bin-dir
            - mountPath: /etc/cni/net.d
              name: cni-net-dir
            - mountPath: /cni/cfg
              name: contiv-cni-cfg
            - mountPath: /var/run/contiv
              name: contiv-run

        {{- if eq .Values.contiv.crdNodeConfigurationDisabled false }}
        # This init container waits until crd node specific configuration has been applied
        - name: wait-forcrdconfig
          env:
          - name: ETCDCTL_API
            value: "3"
          - name: ETCDCTL_ENDPOINTS
          {{- if .Values.etcd.useExternalInstance }}
            value: {{ include "utils.commaseparated" .Values.etcd.externalInstance.endpoints | quote }}
          {{- end }}
          {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
          - name: ETCDCTL_CACERT
            value: "/var/contiv/etcd-secrets/caCert"
          - name: ETCDCTL_CERT
            value: "/var/contiv/etcd-secrets/clientCert"
          - name: ETCDCTL_KEY
            value:  "/var/contiv/etcd-secrets/clientKey"
          {{- else }}
            {{- if .Values.etcd.secureTransport }}
          - name: ETCDCTL_CACERT
            value: "/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.caCert }}"
          - name: ETCDCTL_CERT
            value: "/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientCert }}"
          - name: ETCDCTL_KEY
            value:  "/var/contiv/etcd-secrets/{{ .Values.etcd.secrets.clientKey }}"
            {{- end }}
          {{- end }}
          - name: HOST_IP
          {{- if .Values.etcd.service.useNodeIP }}
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          {{- else }}
            value:  {{ $localhost_addr | quote }}
          {{- end}}
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.etcd_arm64.image.repository }}:{{ .Values.etcd_arm64.image.tag }}
          {{- else }}
          image: {{ .Values.etcd.image.repository }}:{{ .Values.etcd.image.tag }}
          {{- end }}
          command:
          - /bin/sh
          args:
          - -c
          - |
            set -u
            echo "$HOST_IP" | grep -q ':'
            if [ "$?" -eq "0" ];
            then
               HOST_IP="[$HOST_IP]"
            fi
          {{- if not .Values.etcd.useExternalInstance }}
            export ETCDCTL_ENDPOINTS="$HOST_IP:32379"
          {{- end }}
            until /usr/local/bin/etcdctl get "/vnf-agent/contiv-ksr/k8s/nodeconfig/$HOSTNAME" --prefix=true | grep -m 1 "$HOSTNAME";
            do
              echo waiting for crd node config;
              sleep 1
            done
          {{- if .Values.etcd.secureTransport }}
          volumeMounts:
          - name: etcd-secrets
            mountPath: /var/contiv/etcd-secrets
            readOnly: true
          {{- end }}
        {{- end }}

        # This init container extracts/copies default VPP config to the host and initializes VPP core dumps.
        - name: vpp-init
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.vswitch_arm64.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
          {{- else }}
          image: {{ .Values.vswitch.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          command:
            - /bin/sh
          args:
            - -c
            - |
              set -eu
              chmod 700 /run/vpp
              rm -rf /dev/shm/db /dev/shm/global_vm /dev/shm/vpe-api
              if [ ! -e /host/etc/vpp/contiv-vswitch.conf ]; then
                  cp /etc/vpp/contiv-vswitch.conf /host/etc/vpp/
              fi
              if [ ! -d /var/run/contiv ]; then
                  mkdir /var/run/contiv
              fi
              chmod 700 /var/run/contiv
              rm -f /var/run/contiv/cni.sock
              if ip link show vpp1 >/dev/null 2>&1; then
                   ip link del vpp1
              fi
              cp -f /usr/local/bin/vppctl /host/usr/local/bin/vppctl
              {{- if .Values.vswitch.enableCoreDumps }}
              sysctl -w debug.exception-trace=1
              sysctl -w kernel.core_pattern="{{ .Values.vswitch.coreDumpsDir }}/%e-%t"
              ulimit -c unlimited
              echo 2 > /proc/sys/fs/suid_dumpable
              {{- end }}
              # replace localhost IP by node IP since node port doesn't work
              # on localhost IP in a certain scenario
              cp /etc/etcd/etcd.conf /tmp/etcd.conf
              set +e
              echo "$HOST_IP" | grep -q ':'
              if [ "$?" -eq "0" ];
              then
                 HOST_IP="[$HOST_IP]"
              fi
              sed -i "s/__HOST_IP__/$HOST_IP/g" /tmp/etcd.conf
          resources: {}
          securityContext:
            privileged: true
          volumeMounts:
            - name: usr-local-bin
              mountPath: /host/usr/local/bin
            - name: vpp-cfg
              mountPath: /host/etc/vpp
            - name: shm
              mountPath: /dev/shm
            - name: vpp-run
              mountPath: /run/vpp
            - name: contiv-run
              mountPath: /var/run/contiv
            - name: tmp
              mountPath: /tmp
            - name: etcd-cfg
              mountPath: /etc/etcd
            {{- if .Values.vswitch.enableCoreDumps }}
            - name: core-dumps
              mountPath: {{ .Values.vswitch.coreDumpsDir }}
            {{- end }}

      containers:
        # Runs contiv-vswitch container on each Kubernetes node.
        # It contains the vSwitch VPP and its management agent.
        - name: contiv-vswitch
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.vswitch_arm64.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
          {{- else }}
          image: {{ .Values.vswitch.image.repository }}:{{ default .Chart.Version .Values.vswitch.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.vswitch.image.pullPolicy }}
          securityContext:
            privileged: true
          ports:
            # readiness + liveness probe
            - containerPort: {{ .Values.vswitch.httpPort }}
          {{- if .Values.vswitch.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: {{ .Values.vswitch.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.vswitch.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.vswitch.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.vswitch.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.vswitch.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: {{ .Values.vswitch.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.vswitch.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.vswitch.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.vswitch.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.vswitch.livenessProbeInitialDelaySeconds }}
          {{- end }}
          env:
            - name: MICROSERVICE_LABEL
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            {{- if not .Values.vswitch.useSocketVPPConnection }}
            - name: GOVPPMUX_NOSOCK
              value: "1"
            {{- end }}
            - name: CONTIV_CONFIG
              value: "/etc/contiv/contiv.conf"
            - name: CONTROLLER_CONFIG
              value: "/etc/contiv/controller.conf"
            - name: SERVICE_CONFIG
              value: "/etc/contiv/service.conf"
            - name: ETCD_CONFIG
              value: "/tmp/etcd.conf"
            - name: BOLT_CONFIG
              value: "/etc/vpp-agent/bolt.conf"
            # Uncomment to log graph traversal (very verbose):
            # - name: KVSCHED_LOG_GRAPH_WALK
            #   value: "true"
            # Uncomment to verify effect of every transaction:
            # - name: KVSCHED_VERIFY_MODE
            #   value: "true"
            {{- if .Values.bolt.debug }}
            - name: DEBUG_BOLT_CLIENT
              value: "true"
            {{- end}}
            - name: TELEMETRY_CONFIG
              value: "/etc/vpp-agent/telemetry.conf"
            - name: GOVPP_CONFIG
              value: "/etc/vpp-agent/govpp.conf"
            - name: LOGS_CONFIG
              value: "/etc/vpp-agent/logs.conf"
            - name: HTTP_CONFIG
              value: "/etc/vpp-agent/http.conf"
            - name: GRPC_CONFIG
              value: "/etc/vpp-agent/grpc.conf"
            - name: GRPC2_CONFIG
              value: "/etc/vpp-agent/grpc2.conf"
            - name: LINUX_IFPLUGIN_CONFIG
              value: "/etc/vpp-agent/linux-ifplugin.conf"
            - name: LINUX_L3PLUGIN_CONFIG
              value: "/etc/vpp-agent/linux-l3plugin.conf"
            - name: KVSCHEDULER_CONFIG
              value: "/etc/vpp-agent/kvscheduler.conf"
            {{- if eq .Values.vswitch.enableInterfaceStats false }}
            - name: DISABLE_INTERFACE_STATS
              value: "y"
            {{- end}}
          volumeMounts:
            - name: var-bolt
              mountPath: /var/bolt
            - name: etcd-cfg
              mountPath: /etc/etcd
              {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
              {{- else }}
              {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
              {{- end }}
              {{- end }}
              {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
              {{- end }}
            - name: vpp-cfg
              mountPath: /etc/vpp
            - name: shm
              mountPath: /dev/shm
            - name: dev
              mountPath: /dev
            - name: sys-bus-pci
              mountPath: /sys/bus/pci
            - name: vpp-run
              mountPath: /run/vpp
            - name: contiv-run
              mountPath: /var/run/contiv
            - name: contiv-agent-cfg
              mountPath: /etc/contiv
            - name: vpp-agent-cfg
              mountPath: /etc/vpp-agent
            - name: tmp
              mountPath: /tmp
            {{- if .Values.vswitch.enableCoreDumps }}
            - name: core-dumps
              mountPath: {{ .Values.vswitch.coreDumpsDir }}
            {{- end }}
            - name: docker-socket
              mountPath: /var/run/docker.sock
            - name: kubelet-api
              mountPath: /var/lib/kubelet
          resources:
            {{- if or .Values.vswitch.defineMemoryLimits .Values.vswitch.cpuLimit }}
            limits:
            {{- end }}
            {{- if .Values.vswitch.defineMemoryLimits }}
              {{- if .Values.vswitch.hugePages1giLimit }}
              hugepages-1Gi: {{ .Values.vswitch.hugePages1giLimit }}
              {{- else }}
                {{- if .Values.vswitch.hugePages2miLimit }}
              hugepages-2Mi: {{ .Values.vswitch.hugePages2miLimit }}
                {{- end }}
              {{- end }}
              memory: {{ .Values.vswitch.memoryLimit }}
            {{- end }}
            {{- if .Values.vswitch.cpuLimit }}
              cpu: {{ .Values.vswitch.cpuLimit }}
            {{- end }}
            {{- if .Values.vswitch.cpuRequest }}
            requests:
              cpu: {{ .Values.vswitch.cpuRequest }}
            {{- end }}

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-cfg
        {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
        - name: etcd-secrets
          secret:
            secretName: {{ .Values.etcd.externalInstance.secretName }}
            items:
            - key: caCert
              path: caCert
            - key: clientCert
              path: clientCert
            - key: clientKey
              path: clientKey
        {{- else }}
         {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
         {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # VPP startup config folder.
        - name: vpp-cfg
          hostPath:
            path: /etc/vpp
        # To install vppctl.
        - name: usr-local-bin
          hostPath:
            path: /usr/local/bin
        # /dev mount is required for DPDK-managed NICs on VPP (/dev/uio0) and for shared memory communication with VPP (/dev/shm)
        - name: dev
          hostPath:
            path: /dev
        - name: shm
          hostPath:
            path: /dev/shm
        # /sys/bus/pci is required for binding PCI devices to specific drivers
        - name: sys-bus-pci
          hostPath:
            path: /sys/bus/pci
        # For CLI unix socket.
        - name: vpp-run
          hostPath:
            path: /run/vpp
        # For CNI / STN unix domain socket
        - name: contiv-run
          hostPath:
            path: /var/run/contiv
        # Used to configure contiv agent.
        - name: contiv-agent-cfg
          configMap:
            name: contiv-agent-cfg
        # Used to configure vpp agent.
        - name: vpp-agent-cfg
          configMap:
            name: vpp-agent-cfg
        {{- if .Values.vswitch.enableCoreDumps }}
        # Used for vswitch core dumps
        - name: core-dumps
          hostPath:
            path: {{ .Values.vswitch.coreDumpsDir }}
        {{- end }}
        # /tmp in the vswitch container (needs to be persistent between container restarts to obtain post-mortem files)
        - name: tmp
          emptyDir:
            medium: Memory
        # persisted bolt data
        - name: var-bolt
          hostPath:
            path: {{ .Values.bolt.dataDir }}
        - name: docker-socket
          hostPath:
            path: /var/run/docker.sock
        # CNI config
        - name: contiv-cni-cfg
          configMap:
            name: contiv-cni-cfg
        # kubelet api dir
        - name: kubelet-api
          hostPath:
            path: /var/lib/kubelet

---

# This installs the contiv-ksr (Kubernetes State Reflector) on the master node in a Kubernetes cluster.
{{- if .Values.k8sVersion.post_1_9 }}
apiVersion: apps/v1
{{- else }}
apiVersion: extensions/v1beta1
{{- end }}
kind: DaemonSet
metadata:
  name: contiv-ksr
  namespace: kube-system
  labels:
    k8s-app: contiv-ksr
spec:
  selector:
    matchLabels:
      k8s-app: contiv-ksr
  updateStrategy:
    type: {{ .Values.ksr.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-ksr
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true
      # This grants the required permissions to contiv-ksr.
      serviceAccountName: contiv-ksr

      initContainers:
        # This init container waits until etcd is started
        - name: wait-foretcd
          env:
            - name: ETCDPORT
              value: {{ .Values.etcd.service.nodePort | quote }}
            - name: HOST_IP
            {{- if .Values.etcd.service.useNodeIP }}
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            {{- else }}
              value: "127.0.0.1"
            {{- end }}
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.init_arm64.image.repository }}:{{ .Values.init.image.tag }}
          {{- else }}
          image: {{ .Values.init.image.repository }}:{{ .Values.init.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
          args:
            - -c
            - |
              {{- if not .Values.etcd.useExternalInstance }}
              cp /etc/etcd/etcd.conf /tmp/cfg/etcd.conf
              echo "$HOST_IP" | grep -q ':'
              if [ "$?" -eq "0" ];
              then
                 HOST_IP="[$HOST_IP]"
              fi
              sed -i "s/__HOST_IP__/$HOST_IP/g" /tmp/cfg/etcd.conf
              until nc -w 2 $HOST_IP:$ETCDPORT; do echo waiting for etcd; sleep 2; done;
              {{- else }}
              {{- range .Values.etcd.externalInstance.endpoints }}
              until nc -w 2 {{ . }}; do echo waiting for etcd; sleep 2; done;
              {{- end }}
              cp /etc/etcd/etcd.conf /tmp/cfg/etcd.conf
              {{- end }}
          volumeMounts:
            - name: tmp-cfg
              mountPath: /tmp/cfg
            - name: etcd-cfg
              mountPath: /etc/etcd


      containers:
        - name: contiv-ksr
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.ksr_arm64.image.repository }}:{{ default .Chart.Version .Values.ksr.image.tag }}
          {{- else }}
          image: {{ .Values.ksr.image.repository }}:{{ default .Chart.Version .Values.ksr.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.ksr.image.pullPolicy }}
          env:
            - name: ETCD_CONFIG
              value: "/tmp/cfg/etcd.conf"
            - name: HTTP_CONFIG
              value: "/etc/http/http.conf"
          volumeMounts:
            - name: tmp-cfg
              mountPath: /tmp/cfg
            - name: http-cfg
              mountPath: /etc/http
            {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- else }}
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
            {{- end }}
            {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
            {{- end }}
          {{- if .Values.ksr.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: {{ .Values.ksr.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.ksr.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.ksr.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.ksr.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.ksr.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: {{ .Values.ksr.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.ksr.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.ksr.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.ksr.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.ksr.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.ksr.cpuLimit }}
            limits:
              cpu: {{ .Values.ksr.cpuLimit }}
            {{- end }}
            {{- if .Values.ksr.cpuRequest }}
            requests:
              cpu: {{ .Values.ksr.cpuRequest }}
            {{- end }}
      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
          {{- if .Values.etcd.useExternalInstance }}
            name: contiv-etcd-cfg
          {{- else }}
            name: contiv-etcd-withcompact-cfg
          {{- end }}
        - name: tmp-cfg
          emptyDir: {}
        - name: http-cfg
          configMap:
            name: contiv-ksr-http-cfg
        {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
        - name: etcd-secrets
          secret:
            secretName: {{ .Values.etcd.externalInstance.secretName }}
            items:
            - key: caCert
              path: caCert
            - key: clientCert
              path: clientCert
            - key: clientKey
              path: clientKey
        {{- else }}
        {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
        {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}

---

# This cluster role defines a set of permissions required for contiv-ksr.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: contiv-ksr
  namespace: kube-system
rules:
  - apiGroups:
      - ""
      - networking.k8s.io
    resources:
      - pods
      - namespaces
      - networkpolicies
      - services
      - endpoints
      - nodes
    verbs:
      - watch
      - list

---

# This defines a service account for contiv-ksr.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-ksr
  namespace: kube-system

---

# This binds the contiv-ksr cluster role with contiv-ksr service account.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-ksr
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-ksr
subjects:
  - kind: ServiceAccount
    name: contiv-ksr
    namespace: kube-system

---

# This installs the contiv-crd on the master node in a Kubernetes cluster.
{{- if .Values.k8sVersion.post_1_9 }}
apiVersion: apps/v1
{{- else }}
apiVersion: extensions/v1beta1
{{- end }}
kind: DaemonSet
metadata:
  name: contiv-crd
  namespace: kube-system
  labels:
    k8s-app: contiv-crd
spec:
  selector:
    matchLabels:
      k8s-app: contiv-crd
  updateStrategy:
    type: {{ .Values.crd.updateStrategy }}
  template:
    metadata:
      labels:
        k8s-app: contiv-crd
      annotations:
        # Marks this pod as a critical add-on.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
        # We need this to schedule on the master no matter what else is going on, so tolerate everything.
        - key: ''
          operator: Exists
          effect: ''
        # This likely isn't needed due to the above wildcard, but keep it in for now.
        - key: CriticalAddonsOnly
          operator: Exists
      # Only run this pod on the master.
      nodeSelector:
        node-role.kubernetes.io/master: ""
      hostNetwork: true
      # This grants the required permissions to contiv-crd.
      serviceAccountName: contiv-crd

      initContainers:
        # This init container waits until etcd is started
        - name: wait-foretcd
          {{- if not .Values.etcd.useExternalInstance }}
          env:
            - name: ETCDPORT
              value: {{ .Values.etcd.service.nodePort | quote }}
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          {{- end }}
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.init_arm64.image.repository }}:{{ .Values.init.image.tag }}
          {{- else }}
          image: {{ .Values.init.image.repository }}:{{ .Values.init.image.tag }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
          args:
            - -c
            - |
              cp /etc/etcd/etcd.conf /tmp/cfg/etcd.conf
            {{- if not .Values.etcd.useExternalInstance }}
              echo "$HOST_IP" | grep -q ':'
              if [ "$?" -eq "0" ];
              then
                 HOST_IP="[$HOST_IP]"
              fi
              sed -i "s/__HOST_IP__/$HOST_IP/g" /tmp/cfg/etcd.conf
              until nc -w 2 $HOST_IP:$ETCDPORT; do echo waiting for etcd; sleep 2; done;
            {{- else }}
              {{- range .Values.etcd.externalInstance.endpoints }}
              until nc -w 2 {{ . }}; do echo waiting for etcd; sleep 2; done;
              {{- end }}
            {{- end }}
          volumeMounts:
            - name: tmp-cfg
              mountPath: /tmp/cfg
            - name: etcd-cfg
              mountPath: /etc/etcd

        # This init container copies contiv-netctl tool to the host.
        - name: netctl-init
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.crd_arm64.image.repository }}:{{ default .Chart.Version .Values.crd.image.tag }}
          {{- else }}
          image: {{ .Values.crd.image.repository }}:{{ default .Chart.Version .Values.crd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.crd.image.pullPolicy }}
          command:
            - /bin/sh
          args:
            - -c
            - |
              echo '#!/bin/sh
              kubectl get pods -n kube-system | \
                grep contiv-crd | \
                cut -d " " -f 1 | \
                xargs -I{} kubectl exec -n kube-system {} \
                /contiv-netctl "$@"' \
              > /host/usr/local/bin/contiv-netctl || true
              chmod +x /host/usr/local/bin/contiv-netctl || true
          volumeMounts:
            - name: usr-local-bin
              mountPath: /host/usr/local/bin

      containers:
        - name: contiv-crd
          {{- if .Values.Arm64Platform }}
          image: {{ .Values.crd_arm64.image.repository }}:{{ default .Chart.Version .Values.crd.image.tag }}
          {{- else }}
          image: {{ .Values.crd.image.repository }}:{{ default .Chart.Version .Values.crd.image.tag }}
          {{- end }}
          imagePullPolicy: {{ .Values.crd.image.pullPolicy }}
          env:
            - name: ETCD_CONFIG
              value: "/tmp/cfg/etcd.conf"
            - name: HTTP_CONFIG
              value: "/etc/http/http.conf"
            - name: HTTP_CLIENT_CONFIG
              value: "/etc/http/http.client.conf"
            - name: CONTIV_CRD_VALIDATE_INTERVAL
              value: {{ .Values.crd.validateInterval | quote }}
            - name: CONTIV_CRD_VALIDATE_STATE
              value: {{ .Values.crd.validateState | quote }}
          {{- if .Values.crd.disableNetctlREST }}
            - name: DISABLE_NETCTL_REST
              value: "true"
          {{- end }}
          volumeMounts:
            - name: tmp-cfg
              mountPath: /tmp/cfg
            - name: http-cfg
              mountPath: /etc/http
            {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- else }}
            {{- if .Values.etcd.secureTransport }}
            - name: etcd-secrets
              mountPath: /var/contiv/etcd-secrets
              readOnly: true
            {{- end }}
            {{- end }}
            {{- if .Values.http.enableServerCert }}
            - name: http-secrets
              mountPath: /var/http
              readOnly: true
            {{- end }}
            {{- if .Values.crd.enableLivenessReadinessProbes }}
          readinessProbe:
            httpGet:
              path: /readiness
              port: {{ .Values.crd.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.crd.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.crd.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.crd.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.crd.readinessProbeInitialDelaySeconds }}
          livenessProbe:
            httpGet:
              path: /liveness
              port: {{ .Values.crd.httpPort }}
              {{- if .Values.http.enableServerCert }}
              scheme: HTTPS
              {{- end }}
              {{- if .Values.http.enableBasicAuth }}
              httpHeaders:
                - name: Authorization
                  value: "Basic {{ .Values.http.basicAuth | b64enc }}"
              {{- end }}
            periodSeconds: {{ .Values.crd.probePeriodSeconds }}
            timeoutSeconds: {{ .Values.crd.probeTimeoutSeconds }}
            failureThreshold: {{ .Values.crd.probeFailureThreshold }}
            initialDelaySeconds: {{ .Values.crd.livenessProbeInitialDelaySeconds }}
          {{- end }}
          resources:
            {{- if .Values.crd.cpuLimit }}
            limits:
              cpu: {{ .Values.crd.cpuLimit }}
            {{- end }}
            {{- if .Values.crd.cpuRequest }}
            requests:
              cpu: {{ .Values.crd.cpuRequest }}
            {{- end }}

      volumes:
        # Used to connect to contiv-etcd.
        - name: etcd-cfg
          configMap:
            name: contiv-etcd-cfg
        - name: usr-local-bin
          hostPath:
            path: /usr/local/bin
        - name: http-cfg
          configMap:
            name: contiv-crd-http-cfg
        - name: tmp-cfg
          emptyDir: {}
        {{- if and .Values.etcd.useExternalInstance .Values.etcd.externalInstance.secretName }}
        - name: etcd-secrets
          secret:
            secretName: {{ .Values.etcd.externalInstance.secretName }}
            items:
            - key: caCert
              path: caCert
            - key: clientCert
              path: clientCert
            - key: clientKey
              path: clientKey
        {{- else }}
         {{- if .Values.etcd.secureTransport }}
        - name: etcd-secrets
          {{- if .Values.etcd.secrets.mountFromHost }}
          hostPath:
            path: {{ .Values.etcd.secrets.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-etcd-secrets
            items:
            - key: caCert
              path: {{ .Values.etcd.secrets.caCert }}
            - key: clientCert
              path: {{ .Values.etcd.secrets.clientCert }}
            - key: clientKey
              path: {{ .Values.etcd.secrets.clientKey }}
          {{- end }}
         {{- end }}
        {{- end }}
        {{- if .Values.http.enableServerCert }}
        - name: http-secrets
          {{- if .Values.http.mountFromHost }}
          hostPath:
            path: {{ .Values.http.mountDir }}
          {{- else }}
          secret:
            secretName: contiv-http-secrets
            items:
            - key: serverCert
              path: {{ .Values.http.serverCert }}
            - key: serverKey
              path: {{ .Values.http.serverKey }}
          {{- end }}
        {{- end }}
---

# This cluster role defines a set of permissions required for contiv-crd.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: contiv-crd
  namespace: kube-system
rules:
  - apiGroups:
      - apiextensions.k8s.io
      - nodeconfig.contiv.vpp
      - telemetry.contiv.vpp
      - contivpp.io
    resources:
      - customresourcedefinitions
      - telemetryreports
      - nodeconfigs
      - externalinterfaces
      - customnetworks
      - servicefunctionchains
      - customconfigurations
    verbs:
      - "*"

---

# This defines a service account for contiv-crd.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-crd
  namespace: kube-system

---

# This binds the contiv-crd cluster role with contiv-crd service account.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-crd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-crd
subjects:
  - kind: ServiceAccount
    name: contiv-crd
    namespace: kube-system

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: contiv-crd-http-cfg
  namespace: kube-system
data:
  http.conf: |
    endpoint: "{{ $any_addr }}:{{ .Values.crd.httpPort }}"
    {{- if .Values.http.enableServerCert }}
    server-cert-file: /var/http/{{ .Values.http.serverCert }}
    server-key-file: /var/http/{{ .Values.http.serverKey }}
    {{- end }}
    {{- if .Values.http.enableBasicAuth }}
    client-basic-auth:
      - {{ .Values.http.basicAuth | quote }}
    {{- end }}
  http.client.conf: |
    port: 9999
    {{- if .Values.http.enableBasicAuth }}
    basic-auth: {{ .Values.http.basicAuth | quote }}
    {{- end }}
    use-https: {{ .Values.http.enableServerCert }}